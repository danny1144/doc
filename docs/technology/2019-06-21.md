---
title: log process demo
date: '2019-06-01'
type: 技术
tags: 服务端
note: efk日志系统
---
## 简介

> Fluentd负责收集日志,
Fluentd 主要由Input输出、Buffer缓冲、Output输出三大部分组成。这三大部分都是以插件的形式存在。当然还有其他辅助插件如Filter、Formatter等用于数据处理或格式化。输出至elasticsearch依赖插件

> fluent-plugin-elasticsearch,(/opt/td-agent/embedded/bin/fluent-gem install fluent-plugin-elasticsearch)


> Fluentd配置
- source: 数据源配置，可接受log-tail、http、tcp、udp等方式数据，
- filter: 数据过滤配置，对匹配的tag进行过滤
- match: 数据输出配置，对匹配的tag进行输出设置
> Elasticsearch存储日志并提供搜索   
Elasticsearch是个开源分布式搜索引擎，提供搜集、分析、存储数据三大功能。它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。

> Kibana负责日志查询和展示
Kibana可以为 Logstash 、Beats和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助汇总、分析和搜索重要数据日志。
配置index:
　　一般情况下，当启动Kibana的时候会自动搜索可用来展示的索引，如果你需要的没有被搜到，或者如上面新增的数据的索引没有检测到，那么key手动添加索引。配置index的位置为：

::: warning

注意：
 
 1、每次修改fluentd.conf配置文件后。如果涉及索引的新增或者字段新增。需要刷新kibana索引。
 2、logstash.outputs.elasticsearch] retrying failed action with response code: 403 ({"type"=>"cluster_block_exception", "reason"=>"blocked by: [FORBIDDEN/12/index read-only / allow delete (api)]
这是由于ES新节点的数据目录data存储空间不足，导致从master主节点接收同步数据的时候失败，此时ES集群为了保护数据，会自动把索引分片index置为只读read-only
:::
::: tip
解决步骤：
1.提供足够的存储空间供数据写入，如需在配置文件中更改ES数据存储目录，注意重启ES
2.放开索引只读设置，在Kibana的开发工具Dev Tools中执行（或在服务器上通过curl工具发起PUT请求，下文同）

``` js {4}
PUT /_all/_settings

{ 

"index.blocks.read_only_allow_delete": null 

}
```
:::
> logback的配置介绍

Logger、appender及layout

　　Logger作为日志的记录器，把它关联到应用的对应的context上后，主要用于存放日志对象，也可以定义日志类型、级别。

　　Appender主要用于指定日志输出的目的地，目的地可以是控制台、文件、远程套接字服务器、 MySQL、PostreSQL、 Oracle和其他数据库、 JMS和远程UNIX Syslog守护进程等。

　　Layout 负责把事件转换成字符串，格式化的日志信息的输出。

> logger context

　　各个logger 都被关联到一个 LoggerContext，LoggerContext负责制造logger，也负责以树结构排列各logger。其他所有logger也通过org.slf4j.LoggerFactory 类的静态方法getLogger取得。 getLogger方法以 logger名称为参数。用同一名字调用LoggerFactory.getLogger 方法所得到的永远都是同一个logger对象的引用。

> 有效级别及级别的继承

　　Logger 可以被分配级别。级别包括：TRACE、DEBUG、INFO、WARN 和 ERROR，定义于ch.qos.logback.classic.Level类。如果 logger没有被分配级别，那么它将从有被分配级别的最近的祖先那里继承级别。root logger 默认级别是 DEBUG。

> 打印方法与基本的选择规则

打印方法决定记录请求的级别。例如，如果 L 是一个 logger 实例，那么，语句 L.info("..")是一条级别为 INFO的记录语句。记录请求的级别在高于或等于其 logger 的有效级别时被称为被启用，否则，称为被禁用。记录请求级别为 p，其 logger的有效级别为 q，只有则当 p>=q时，该请求才会被执行。

该规则是 logback 的核心。级别排序为： TRACE < DEBUG < INFO < WARN < ERROR

 logback配置文件
``` xml
<?xml version="1.0" encoding="ISO-8859-1"?>

<configuration  scan="true" scanPeriod="5 minutes">

    <conversionRule conversionWord="serverIp" converterClass="com.siemens.ofmasset.common.log.ServerIp"/>

    <conversionRule conversionWord="serverName" converterClass="com.siemens.ofmasset.common.log.ServerName"/>

    <conversionRule conversionWord="operationType" converterClass="com.siemens.ofmasset.common.log.OperationType"/>

    <conversionRule conversionWord="operationContent" converterClass="com.siemens.ofmasset.common.log.OperationContiant"/>

    <contextName>dpp</contextName>



    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">

        <encoder>

            <Pattern>[%d{yyyy-MM-dd HH:mm:ss Z}] [%-5level] [dpp] [ofm-asset] [%serverName] [%serverIp] [%logger{36}] [%operationType] [%operationContent] [] [thread-%thread] %n</Pattern>

        </encoder>

    </appender>

<appender name="FLUENT_TEXT"

class="ch.qos.logback.more.appenders.FluentLogbackAppender">

<!-- Tag for Fluentd. Farther information: http://docs.fluentd.org/articles/config-file -->

<tag>ofm-asset</tag>

<!-- [Optional] Label for Fluentd. Farther information: http://docs.fluentd.org/articles/config-file -->

<!-- Host name/address and port number which Flentd placed -->

<remoteHost>10.192.30.192</remoteHost>

<port>24224</port>

<!-- Max queue size of logs which is waiting to be sent (When it reach

to the max size, the log will be disappeared). -->

<maxQueueSize>999999</maxQueueSize>

<layout class="com.siemens.ofmasset.common.log.AssetPatternLayout">

          <Pattern>[%d{yyyy-MM-dd HH:mm:ss Z}] [%-5level] [dpp] [ofm-asset] [%serverName] [%serverIp] [%logger{36}] [%operationType] [%operationContent] [] [thread-%thread] %n</Pattern>

</layout>

</appender>

<logger name="druid.sql" level="INFO"/>

<logger name="com.alibaba.druid" level="INFO"/>

<logger name="access" level="INFO"/>

<logger name="service" level="INFO"/>

    <logger name="logback"/>



    <logger name="com.siemens" level="info" additivity="true">

<appender-ref ref="FLUENT_TEXT" />

</logger>

    <root level="info">

        <appender-ref ref="STDOUT" />

    </root>

</configuration>
```
fluentd配置文件
``` js

<source>

  @type forward

  port 24224

</source>

<source>

  @type http

  port 8081

</source>

<system>

  #  处理10亿级别的日志输入时，CPU会出现瓶颈，这时考虑增加工作进程数量：

  workers 8

</system>

<filter ofm-asset>

    @type record_transformer

    enable_ruby

# 从[%d{yyyy-MM-dd HH:mm:ss Z}] [%-5level] [dpp] [ofm-asset] [%serverName] [%serverIp] [%logger{36}] [%operationType] [%operationContent] [] [thread-%thread] %n

    # 形式的Logback Pattern中抽取字段,用于过滤查询

  <record>

      level  ${record["msg"][29,5].strip}

    </record>

  </filter>

<match *.**>

  type copy

  # 输出到elasticsearch

  <store>

    @type elasticsearch

    host 10.192.30.192

    port 9200

    logstash_format true

    logstash_prefix fluentd-${tag}

    logstash_dateformat %Y%m%d

    include_tag_key true

    type_name access_log

    tag_key log_name

    level

    flush_interval 10s

  flush_thread_count  10

</store>

# 用于控制台输出

<store>

    @type stdout

  </store>

</match>
```
 java测试代码

  maven依赖：
``` xml
<dependency>
			<groupId>com.sndyuk</groupId>
			<artifactId>logback-more-appenders</artifactId>
			<version>1.5.6</version>
		</dependency>
		<dependency>
			<groupId>org.fluentd</groupId>
			<artifactId>fluent-logger</artifactId>
			<version>${fluentd.logger.version}</version>
			<optional>true</optional>
		</dependency>

```
``` js
   
@Slf4j

public class TestLogController {

  @GetMapping("info")

    public String info() {

  log.info("info msg");

        return "info";

    }

  @GetMapping("warn")

    public String warn() {

  log.warn("warn msg");

        return "warn";

    }

  @GetMapping("error")

    public String error() {

  log.error("info msg");-

        return "error";

    }

}
```

测试请求打印日志如下
```js

- curl http://localhost:8009/asset//log/info

- curl http://localhost:8009/asset//log/warn

- curl http://localhost:8009/asset//log/error
```

日志记录：

- [WARN:](http://10.192.30.192:5601/app/kibana#/discover/7c0c88a0-9325-11e9-91cb-af2618cf1d31?_g=(refreshInterval%3A(display%3AOff%2Cpause%3A!f%2Cvalue%3A0)%2Ctime%3A(from%3Anow%2Fd%2Cmode%3Aquick%2Cto%3Anow%2Fd)))

- [ERROR:](http://10.192.30.192:5601/app/kibana#/discover/9bb1bae0-9325-11e9-91cb-af2618cf1d31?_g=(refreshInterval%3A(display%3AOff%2Cpause%3A!f%2Cvalue%3A0)%2Ctime%3A(from%3Anow%2Fd%2Cmode%3Aquick%2Cto%3Anow%2Fd)))

- [INFO:](http://10.192.30.192:5601/app/kibana#/discover/150a2b80-92fd-11e9-91cb-af2618cf1d31?_g=(refreshInterval%3A(display%3AOff%2Cpause%3A!f%2Cvalue%3A0)%2Ctime%3A(from%3Anow%2Fd%2Cmode%3Aquick%2Cto%3Anow%2Fd)))

## 参考资料

- 1、[绿色联盟](https://blog.gmem.cc/efk-as-a-log-analysis-system)

- 2、[官方网站](https://docs.fluentd.org/deployment/logging#per-plugin-log)